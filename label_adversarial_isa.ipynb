{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet neural-structured-learning\n",
    "import matplotlib.pyplot as plt\n",
    "import neural_structured_learning as nsl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create TFrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = \"/data/isabelle/wzs_p1_dip/metadata/p1-dip-metadata_1130.db\"\n",
    "output_tfrecord = \"/data/isabelle/wzs_p1_dip/tfrecord\"\n",
    "TABEL_DEGREE_TXT = \"/data/isabelle/wzs_p1_dip/table_degree.txt\"\n",
    "TABEL_LABEL_TXT = \"/data/isabelle/wzs_p1_dip/table_label.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DEGREE = 4\n",
    "N_LABEL = 2\n",
    "\n",
    "table_degree = tf.lookup.StaticHashTable(tf.lookup.TextFileInitializer(\n",
    "    TABEL_DEGREE_TXT,\n",
    "    tf.string, tf.lookup.TextFileIndex.WHOLE_LINE,\n",
    "    tf.int64, tf.lookup.TextFileIndex.LINE_NUMBER\n",
    "), N_DEGREE)\n",
    "table_label = tf.lookup.StaticHashTable(tf.lookup.TextFileInitializer(\n",
    "    TABEL_LABEL_TXT,\n",
    "    tf.string, tf.lookup.TextFileIndex.WHOLE_LINE,\n",
    "    tf.int64, tf.lookup.TextFileIndex.LINE_NUMBER\n",
    "), N_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def parse_fn(path, label, degree):\n",
    "    img_byte_str = tf.io.read_file(path)\n",
    "    label = table_label.lookup(label)\n",
    "    degree = table_degree.lookup(degree)\n",
    "    return img_byte_str, label, degree\n",
    "\n",
    "def create_example(img_byte_str, label, degree):\n",
    "    features = {\n",
    "        \"image\": _bytes_feature(img_byte_str),\n",
    "        \"degree\": _int64_feature(degree),\n",
    "        \"label\": _int64_feature(label),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tf.data.experimental.SqlDataset(driver_name, data_source_name, query, output_types)\n",
    "\n",
    "labels = [\n",
    "    'NG',\n",
    "    'OK',\n",
    "]\n",
    "\n",
    "for label in labels:\n",
    "    dataset = tf.data.experimental.SqlDataset(\n",
    "        \"sqlite\", DB_PATH,\n",
    "        f\"\"\"select path, label, degree from metadata\n",
    "        where\n",
    "            label = '{label}' and\n",
    "            degree >= 0 and\n",
    "            component_class = 'label'\n",
    "        \"\"\", (tf.string, tf.string, tf.string))\n",
    "# Once you have a Dataset object, you can transform it into a new Dataset by \n",
    "# chaining method calls on the tf.data.Dataset object. \n",
    "# For example, you can apply per-element transformations such as Dataset.map(), \n",
    "# and multi-element transformations such as Dataset.batch().#\n",
    "# map(map_func, num_parallel_calls=None, deterministic=None)\n",
    "    \n",
    "    dataset = dataset.map(parse_fn, tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    tfrecord_path = f\"{output_tfrecord}/{label}.tfrecord\"\n",
    "    with tf.io.TFRecordWriter(tfrecord_path) as writer:\n",
    "        for img_byte_str, label, degree in dataset:\n",
    "            example = create_example([img_byte_str.numpy()], [label.numpy()], [degree.numpy()])\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParam():\n",
    "    def __init__(self):\n",
    "        self.channels = 3\n",
    "        self.image_size = 32\n",
    "        self.input_shape = (self.image_size, self.image_size, self.channels)\n",
    "        \n",
    "        self.shuffle_buffer = 10000\n",
    "        self.batch_size = 1024\n",
    "        self.valid_size = 3000\n",
    "        \n",
    "        self.epochs = 10\n",
    "        self.steps_per_epoch = 100\n",
    "        \n",
    "        self.adv_multiplier = 2e-1\n",
    "        self.adv_step_size = 2e-1\n",
    "\n",
    "hparam = HParam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tutorials/adversarial_keras_cnn_HParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "      def __init__(self):\n",
    "        self.channels = 3\n",
    "        self.image_size = 32\n",
    "        self.input_shape = [32, 32, 3]\n",
    "        self.num_classes = 2\n",
    "        self.conv_filters = [64, 128, 256]\n",
    "        self.kernel_size = 3\n",
    "        self.pool_size = (2, 2)\n",
    "        self.num_fc_units = [64]\n",
    "        self.shuffle_buffer = 1000\n",
    "        self.batch_size = 500\n",
    "        self.epochs = 100\n",
    "        self.steps_per_epoch = 100\n",
    "        self.valid_size = 4000\n",
    "        self.adv_multiplier = 0.2\n",
    "        self.adv_step_size = 0.2\n",
    "        self.adv_grad_norm = 'infinity'\n",
    "\n",
    "HPARAMS = HParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_model(hparams):\n",
    "  #\"\"\"Builds a model according to the architecture defined in `hparams`.\"\"\"\n",
    "    inputs = tf.keras.Input(\n",
    "          shape=hparams.input_shape)\n",
    "    x = inputs\n",
    "    for i, num_filters in enumerate(hparams.conv_filters):\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            num_filters, hparams.kernel_size, padding=\"same\", activation='relu')(\n",
    "                x)\n",
    "        if i < len(hparams.conv_filters) - 1:\n",
    "          # max pooling between convolutional layers\n",
    "          x = tf.keras.layers.MaxPooling2D(hparams.pool_size)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    for num_units in hparams.num_fc_units:\n",
    "        x = tf.keras.layers.Dense(num_units, activation='relu')(x)\n",
    "    pred = tf.keras.layers.Dense(hparams.num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=pred)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1048640   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,419,586\n",
      "Trainable params: 1,419,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_base_model(HPARAMS).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(image):\n",
    "    image = tf.io.decode_jpeg(image, HPARAMS.channels)\n",
    "    image = tf.image.resize_with_pad(image, HPARAMS.image_size, HPARAMS.image_size)\n",
    "    return image\n",
    "\n",
    "def parse_single_example(example_proto):\n",
    "    feature_spec = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        ##\"degree\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    features = tf.io.parse_single_example(example_proto, feature_spec)\n",
    "\n",
    "    features[\"image\"] = parse_image(features[\"image\"])\n",
    "    ##features[\"degree\"] = tf.one_hot(features[\"degree\"], N_DEGREE)\n",
    "    features[\"label\"] = tf.one_hot(features[\"label\"], N_LABEL)\n",
    "\n",
    "    label = features[\"label\"]\n",
    "    return features, label\n",
    "\n",
    "def convert_for_adv(features, label):\n",
    "    return {\n",
    "        \"label\": tf.cast(label, tf.float32),\n",
    "        ##\"degree\": tf.cast(features[\"degree\"], tf.float32),\n",
    "        \"image\": features[\"image\"],\n",
    "    }\n",
    "\n",
    "tfrecord_paths = [\n",
    "    \"/data/isabelle/wzs_p1_dip/tfrecord/NG.tfrecord\",\n",
    "    \"/data/isabelle/wzs_p1_dip/tfrecord/OK.tfrecord\"\n",
    "]\n",
    "datasets = [tf.data.TFRecordDataset(x).repeat() for x in tfrecord_paths]\n",
    "dataset = tf.data.experimental.sample_from_datasets(datasets)\n",
    "##You use the methods on SqlDataset to manipulate the data. For example, create a train/test split with:\n",
    "train_ds = dataset.skip(HPARAMS.valid_size).shuffle(HPARAMS.shuffle_buffer).map(parse_single_example, tf.data.experimental.AUTOTUNE).batch(HPARAMS.batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_ds = dataset.take(HPARAMS.valid_size).shuffle(HPARAMS.shuffle_buffer).map(parse_single_example, tf.data.experimental.AUTOTUNE).batch(HPARAMS.batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ({image: (None, 32, 32, 3), label: (None, 2)}, (None, 2)), types: ({image: tf.float32, label: tf.float32}, tf.float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['image', 'label'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 11s 113ms/step - loss: 4.8729 - categorical_accuracy: 0.9056 - val_loss: 0.3017 - val_categorical_accuracy: 0.8655\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 10s 104ms/step - loss: 0.0463 - categorical_accuracy: 0.9864 - val_loss: 1.4834 - val_categorical_accuracy: 0.6090\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.0162 - categorical_accuracy: 0.9946 - val_loss: 1.4769 - val_categorical_accuracy: 0.7207\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.0126 - categorical_accuracy: 0.9961 - val_loss: 0.0464 - val_categorical_accuracy: 0.9868\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.0065 - categorical_accuracy: 0.9986 - val_loss: 0.0098 - val_categorical_accuracy: 0.9975\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.0026 - categorical_accuracy: 0.9996 - val_loss: 0.0025 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.0013 - categorical_accuracy: 0.9999 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 6.8403e-04 - categorical_accuracy: 0.9999 - val_loss: 0.0043 - val_categorical_accuracy: 0.9992\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 5.2926e-04 - categorical_accuracy: 1.0000 - val_loss: 9.6880e-04 - val_categorical_accuracy: 0.9998\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 3.0357e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0026 - val_categorical_accuracy: 0.9995\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 11s 107ms/step - loss: 2.2087e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0032 - val_categorical_accuracy: 0.9990\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 1.4387e-04 - categorical_accuracy: 1.0000 - val_loss: 1.3589e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 7.5731e-05 - categorical_accuracy: 1.0000 - val_loss: 1.3278e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 5.5086e-05 - categorical_accuracy: 1.0000 - val_loss: 6.3636e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 3.1254e-05 - categorical_accuracy: 1.0000 - val_loss: 2.6345e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 2.0899e-05 - categorical_accuracy: 1.0000 - val_loss: 2.0884e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 11s 107ms/step - loss: 1.4513e-05 - categorical_accuracy: 1.0000 - val_loss: 2.4712e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 1.4218e-05 - categorical_accuracy: 1.0000 - val_loss: 1.5586e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 1.0782e-05 - categorical_accuracy: 1.0000 - val_loss: 1.3322e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 9.0958e-06 - categorical_accuracy: 1.0000 - val_loss: 1.0252e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 7.5175e-06 - categorical_accuracy: 1.0000 - val_loss: 8.1374e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 6.6443e-06 - categorical_accuracy: 1.0000 - val_loss: 7.4146e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 5.2134e-06 - categorical_accuracy: 1.0000 - val_loss: 8.6462e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 5.0135e-06 - categorical_accuracy: 1.0000 - val_loss: 8.2661e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 4.2507e-06 - categorical_accuracy: 1.0000 - val_loss: 7.3222e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 4.1469e-06 - categorical_accuracy: 1.0000 - val_loss: 4.8655e-06 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      " 82/100 [=======================>......] - ETA: 1s - loss: 3.2968e-06 - categorical_accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-c6ef772206d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m base_model.fit(train_ds, validation_data=valid_ds,\n\u001b[1;32m      9\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHPARAMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHPARAMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           callbacks=[callback, callback_TB], verbose=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logdir = \"/data/isabelle/wzs_p1_dip/base_model_isa\"\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "callback_TB = tf.keras.callbacks.TensorBoard(logdir, write_graph=False, profile_batch=0)\n",
    "base_model = build_base_model(HPARAMS)\n",
    "base_model.compile(\"adam\", \"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "base_model.fit(train_ds, validation_data=valid_ds,\n",
    "          epochs=HPARAMS.epochs,steps_per_epoch=HPARAMS.steps_per_epoch,\n",
    "          callbacks=[callback, callback_TB], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 100ms/step - loss: 4.4581e-06 - categorical_accuracy: 1.0000\n",
      "\n",
      "accuracy: {'loss': 4.458062448975397e-06, 'categorical_accuracy': 1.0}\n"
     ]
    }
   ],
   "source": [
    "results = base_model.evaluate(valid_ds)\n",
    "named_results = dict(zip(base_model.metrics_names, results))\n",
    "print('\\naccuracy:', named_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 5.7198203e-17]\n",
      " [1.2896402e-09 1.0000000e+00]\n",
      " [1.0000000e+00 1.9448763e-13]\n",
      " ...\n",
      " [6.2181277e-15 1.0000000e+00]\n",
      " [1.0000000e+00 4.3265480e-10]\n",
      " [5.4323043e-12 1.0000000e+00]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_pred = base_model.predict(valid_ds)\n",
    "print(y_pred)\n",
    "print(type(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = valid_ds.as_numpy_iterator().next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "count = 0\n",
    "prediction = base_model.predict(valid_ds)\n",
    "batch = label_batch.shape[0]\n",
    "for i in range(batch):\n",
    "    count += 1\n",
    "    if np.argmax(label_batch[i]) == 0:\n",
    "        y_true.append('NG')\n",
    "    else:\n",
    "        y_true.append('OK')\n",
    "    if np.argmax(prediction[i]) == 0:\n",
    "        y_pred.append('NG')\n",
    "    else:\n",
    "        y_pred.append('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          \n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            c = cm[j,i]\n",
    "            ax.text(i, j, str(c), va='center', ha='center')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_true, y_pred, labels=[\"NG\", \"OK\"])\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=[\"NG\", \"OK\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on TF.math.confusion matrix(Fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "count = 0\n",
    "prediction = base_model.predict(valid_ds)\n",
    "\n",
    "for i in range(5):\n",
    "    count += 1\n",
    "    if np.argmax(label_batch[i]) == 0:\n",
    "        y_true.append('NG')\n",
    "    else:\n",
    "        y_true.append('OK')\n",
    "    if np.argmax(prediction[i]) == 0:\n",
    "        y_pred.append('NG')\n",
    "    else:\n",
    "        y_pred.append('OK')\n",
    "    print(\"y_true:\", label_batch[i],\"y_pred:\", prediction[i])\n",
    "print(\"y_true:\", y_true, \"y_pred:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shapes of all inputs must match: values[0].shape = [500,2] != values[1].shape = [4000,2] [Op:Pack] name: stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-c0034ea61c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcon_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/confusion_matrix.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(labels, predictions, num_classes, weights, dtype, name)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     values = (array_ops.ones_like(predictions, dtype)\n\u001b[1;32m    196\u001b[0m               if weights is None else weights)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                        (axis, -expanded_num_dims, expanded_num_dims))\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6457\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6458\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6459\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6461\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [500,2] != values[1].shape = [4000,2] [Op:Pack] name: stack"
     ]
    }
   ],
   "source": [
    "con_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from Robert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParam():\n",
    "    def __init__(self):\n",
    "        self.channels = 3\n",
    "        self.image_size = 32\n",
    "        self.input_shape = (self.image_size, self.image_size, self.channels)\n",
    "        \n",
    "        self.shuffle_buffer = 10000\n",
    "        self.batch_size = 1024\n",
    "        self.valid_size = 3000\n",
    "        \n",
    "        self.epochs = 100\n",
    "        self.steps_per_epoch = 100\n",
    "        \n",
    "        self.adv_multiplier = 2e-1\n",
    "        self.adv_step_size = 2e-1\n",
    "\n",
    "hparam = HParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as l\n",
    "\n",
    "def BaseModel():\n",
    "    inputs = {\n",
    "        \"image\": tf.keras.Input(hparam.input_shape, name=\"image\"),\n",
    "        \"degree\": tf.keras.Input([N_DEGREE], name=\"degree\")\n",
    "    }\n",
    "    e = inputs[\"degree\"]\n",
    "    \n",
    "    x = inputs[\"image\"]\n",
    "    x = l.Conv2D(64, 7, padding=\"same\")(x)\n",
    "    x = l.ReLU()(x)\n",
    "    for filters in [128, 256, 512]:\n",
    "        x = l.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = l.BatchNormalization()(x)\n",
    "        x = l.ReLU()(x)\n",
    "        x = l.MaxPool2D()(x)\n",
    "    x = l.Conv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = l.BatchNormalization()(x)\n",
    "    x = l.ReLU()(x)\n",
    "    x = l.GlobalAveragePooling2D()(x)\n",
    "    x = l.Concatenate()([x, e])\n",
    "    x = l.Dense(N_LABEL)(x)\n",
    "    output = l.Activation(\"softmax\", dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tf.keras.metrics.Recall(name=\"recall/NG-InversePolarity\", class_id=0),\n",
    "    tf.keras.metrics.Recall(name=\"recall/NG-MoreComp\", class_id=1),\n",
    "    tf.keras.metrics.Recall(name=\"recall/NG-NoneComp\", class_id=2),\n",
    "    tf.keras.metrics.Recall(name=\"recall/NG-OutsidePosition\", class_id=3),\n",
    "    tf.keras.metrics.Recall(name=\"recall/NG-UpsideDown\", class_id=4),\n",
    "    tf.keras.metrics.Recall(name=\"recall/OK\", class_id=5),\n",
    "    tf.keras.metrics.Precision(name=\"precision/NG-InversePolarity\", class_id=0),\n",
    "    tf.keras.metrics.Precision(name=\"precision/NG-MoreComp\", class_id=1),\n",
    "    tf.keras.metrics.Precision(name=\"precision/NG-NoneComp\", class_id=2),\n",
    "    tf.keras.metrics.Precision(name=\"precision/NG-OutsidePosition\", class_id=3),\n",
    "    tf.keras.metrics.Precision(name=\"precision/NG-UpsideDown\", class_id=4),\n",
    "    tf.keras.metrics.Precision(name=\"precision/OK\", class_id=5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 64)   9472        image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 32, 32, 64)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 128)  73856       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 16, 16, 128)  0           re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 256)  1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 16, 16, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 256)    0           re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 512)    1180160     max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 512)    2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 8, 8, 512)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 4, 4, 512)    0           re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 1024)   4719616     max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 1024)   4096        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 4, 4, 1024)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1024)         0           re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "degree (InputLayer)             [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1028)         0           global_average_pooling2d_2[0][0] \n",
      "                                                                 degree[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            2058        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2)            0           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,288,010\n",
      "Trainable params: 6,284,170\n",
      "Non-trainable params: 3,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bm = BaseModel()\n",
    "bm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"/data/isabelle/wzs_p1_dip/base_model\"\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(logdir, write_graph=False, profile_batch=0)\n",
    "]\n",
    "\n",
    "bm = BaseModel()\n",
    "bm.compile(\"adam\", \"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "bm.fit(train_ds, validation_data=valid_ds,\n",
    "          epochs=hparam.epochs, steps_per_epoch=hparam.steps_per_epoch,\n",
    "          callbacks=callbacks,\n",
    "          verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 03:02:38.557829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "TensorBoard 2.3.0 at http://tensorflow2-jupyter-59998cc8fb-rcds8:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --bind_all --logdir=/data/isabelle/wzs_p1_dip/base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## degree+NG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('label', '000', 'OK', 15447),\n",
       " ('label', '090', 'OK', 1682),\n",
       " ('label', '180', 'OK', 2846),\n",
       " ('label', '270', 'OK', 1656),\n",
       " ('label', 'NG', 'NG', 1142)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_PATH = \"/data/isabelle/wzs_p1_dip/metadata/p1-dip-metadata_1130.db\"\n",
    "output_tfrecord = \"/data/isabelle/wzs_p1_dip/tfrecord/degree_NG\"\n",
    "TABEL_DEGREE_TXT = \"/data/isabelle/wzs_p1_dip/degree_NG/table_degree.txt\"\n",
    "TABEL_LABEL_TXT = \"/data/isabelle/wzs_p1_dip/table_label.txt\"\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "c = conn.cursor()\n",
    "c.execute(\"\"\"select component_class, degree, label, count(*) from metadata \n",
    "    where\n",
    "        (component_class = 'label' )\n",
    "        group by component_class, degree, label\n",
    "        \"\"\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DEGREE = 5\n",
    "N_LABEL = 2\n",
    "\n",
    "table_degree = tf.lookup.StaticHashTable(tf.lookup.TextFileInitializer(\n",
    "    TABEL_DEGREE_TXT,\n",
    "    tf.string, tf.lookup.TextFileIndex.WHOLE_LINE,\n",
    "    tf.int64, tf.lookup.TextFileIndex.LINE_NUMBER\n",
    "), N_DEGREE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tf.data.experimental.SqlDataset(driver_name, data_source_name, query, output_types)\n",
    "\n",
    "degrees = ['000','090','180','270','NG']\n",
    "\n",
    "for degree in degrees:\n",
    "    dataset = tf.data.experimental.SqlDataset(\n",
    "        \"sqlite\", DB_PATH,\n",
    "        f\"\"\"select path, label, degree from metadata\n",
    "        where\n",
    "            degree = '{degree}' and\n",
    "            component_class = 'label'\n",
    "        \"\"\", (tf.string, tf.string, tf.string))\n",
    "# Once you have a Dataset object, you can transform it into a new Dataset by \n",
    "# chaining method calls on the tf.data.Dataset object. \n",
    "# For example, you can apply per-element transformations such as Dataset.map(), \n",
    "# and multi-element transformations such as Dataset.batch().#\n",
    "# map(map_func, num_parallel_calls=None, deterministic=None)\n",
    "    \n",
    "    dataset = dataset.map(parse_fn, tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    tfrecord_path = f\"{output_tfrecord}/{degree}.tfrecord\"\n",
    "    with tf.io.TFRecordWriter(tfrecord_path) as writer:\n",
    "        for img_byte_str, label, degree in dataset:\n",
    "            example = create_example([img_byte_str.numpy()], [label.numpy()], [degree.numpy()])\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_structure(model, input_shape, label_num):\n",
    "    inputs = {\n",
    "        'image': tf.keras.Input(input_shape, name='image'),\n",
    "    }\n",
    "\n",
    "    x = inputs['image']\n",
    "\n",
    "    if model == \"InceptionV3\":\n",
    "        model_body = tf.keras.applications.InceptionV3(input_shape=input_shape, \n",
    "            include_top=False, weights=None)\n",
    "    elif model == \"MobileNetV2\":\n",
    "        model_body = tf.keras.applications.MobileNetV2(input_shape=input_shape, \n",
    "            include_top=False, weights=None)\n",
    "    elif model == \"ResNet50V2\":\n",
    "        model_body = tf.keras.applications.ResNet50V2(input_shape=input_shape, \n",
    "            include_top=False, weights=None)\n",
    "    elif model == \"ResNet50\":\n",
    "        model_body = tf.keras.applications.ResNet50(input_shape=input_shape, \n",
    "            include_top=False, weights=None)\n",
    "    elif model == \"DenseNet121\":\n",
    "        model_body = tf.keras.applications.DenseNet121(input_shape=input_shape, \n",
    "            include_top=False, weights=None)\n",
    "    elif model == \"InceptionResNetV2\":\n",
    "        model_body = tf.keras.applications.InceptionResNetV2(input_shape=input_shape, \n",
    "            include_top=False, weights=None)\n",
    "    elif model == \"VGG16\":\n",
    "        model_body = tf.keras.applications.VGG16(input_shape=input_shape, \n",
    "            include_top=False, weights=None)\n",
    "    elif model == \"Xception\":\n",
    "        model_body = tf.keras.applications.Xception(input_shape=input_shape, \n",
    "            include_top=False, weights=None)\n",
    "\n",
    "    for layer in model_body.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = model_body(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "#     x = tf.keras.layers.Dense(128, name='dense_logits_128')(x)\n",
    "    x = tf.keras.layers.Dense(label_num, name='dense_logits')(x)\n",
    "    x = tf.keras.layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_logits (Dense)         (None, 5)                 10245     \n",
      "_________________________________________________________________\n",
      "predictions (Activation)     (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 23,597,957\n",
      "Trainable params: 23,544,837\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ms = model_structure(\"ResNet50\", [32,32,3], 5)\n",
    "ms.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(image):\n",
    "    image = tf.io.decode_jpeg(image, HPARAMS.channels)\n",
    "    image = tf.image.resize_with_pad(image, 75, 75)\n",
    "    return image\n",
    "\n",
    "def parse_single_example(example_proto):\n",
    "    feature_spec = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"degree\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        ##\"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    features = tf.io.parse_single_example(example_proto, feature_spec)\n",
    "\n",
    "    features[\"image\"] = parse_image(features[\"image\"])\n",
    "    features[\"degree\"] = tf.one_hot(features[\"degree\"], N_DEGREE)\n",
    "    ##features[\"label\"] = tf.one_hot(features[\"label\"], N_LABEL)\n",
    "\n",
    "    label = features[\"degree\"]\n",
    "    return features, label\n",
    "\n",
    "def convert_for_adv(features, label):\n",
    "    return {\n",
    "        ##\"label\": tf.cast(label, tf.float32),\n",
    "        \"degree\": tf.cast(features[\"degree\"], tf.float32),\n",
    "        \"image\": features[\"image\"],\n",
    "    }\n",
    "\n",
    "tfrecord_paths = [\n",
    "    \"/data/isabelle/wzs_p1_dip/tfrecord/degree_NG/NG.tfrecord\",\n",
    "    \"/data/isabelle/wzs_p1_dip/tfrecord/degree_NG/000.tfrecord\",\n",
    "    \"/data/isabelle/wzs_p1_dip/tfrecord/degree_NG/090.tfrecord\",\n",
    "    \"/data/isabelle/wzs_p1_dip/tfrecord/degree_NG/180.tfrecord\",\n",
    "    \"/data/isabelle/wzs_p1_dip/tfrecord/degree_NG/270.tfrecord\",\n",
    "]\n",
    "datasets = [tf.data.TFRecordDataset(x).repeat() for x in tfrecord_paths]\n",
    "dataset = tf.data.experimental.sample_from_datasets(datasets)\n",
    "##You use the methods on SqlDataset to manipulate the data. For example, create a train/test split with:\n",
    "train_ds_degree = dataset.skip(HPARAMS.valid_size).shuffle(HPARAMS.shuffle_buffer).map(parse_single_example, tf.data.experimental.AUTOTUNE).batch(HPARAMS.batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_ds_degree = dataset.take(HPARAMS.valid_size).shuffle(HPARAMS.shuffle_buffer).map(parse_single_example, tf.data.experimental.AUTOTUNE).batch(HPARAMS.batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ({degree: (None, 5), image: (None, 75, 75, 3)}, (None, 5)), types: ({degree: tf.float32, image: tf.float32}, tf.float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.Recall(name=\"recall/000\", class_id=0),\n",
    "    tf.keras.metrics.Recall(name=\"recall/090\", class_id=1),\n",
    "    tf.keras.metrics.Recall(name=\"recall/180\", class_id=2),\n",
    "    tf.keras.metrics.Recall(name=\"recall/270\", class_id=3),\n",
    "    tf.keras.metrics.Recall(name=\"recall/NG\", class_id=4),\n",
    "    tf.keras.metrics.Precision(name=\"precision/000\", class_id=0),\n",
    "    tf.keras.metrics.Precision(name=\"precision/090\", class_id=1),\n",
    "    tf.keras.metrics.Precision(name=\"precision/180\", class_id=2),\n",
    "    tf.keras.metrics.Precision(name=\"precision/270\", class_id=3),\n",
    "    tf.keras.metrics.Precision(name=\"precision/NG\", class_id=4),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.2684 - recall/000: 0.0000e+00 - recall/090: 0.8600 - recall/180: 0.8533 - recall/270: 0.0000e+00 - recall/NG: 0.9343 - precision/000: 0.0000e+00 - precision/090: 0.7783 - precision/180: 0.7905 - precision/270: 0.0000e+00 - precision/NG: 0.8585 - val_loss: 0.9113 - val_recall/000: 0.0000e+00 - val_recall/090: 0.0025 - val_recall/180: 0.0988 - val_recall/270: 0.0000e+00 - val_recall/NG: 0.1176 - val_precision/000: 0.0000e+00 - val_precision/090: 0.5000 - val_precision/180: 0.0492 - val_precision/270: 0.0000e+00 - val_precision/NG: 0.0533\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.5094 - recall/000: 0.0000e+00 - recall/090: 0.1487 - recall/180: 0.1341 - recall/270: 0.0000e+00 - recall/NG: 0.8248 - precision/000: 0.0000e+00 - precision/090: 0.3412 - precision/180: 0.4585 - precision/270: 0.0000e+00 - precision/NG: 0.8957 - val_loss: 1.6842 - val_recall/000: 0.0000e+00 - val_recall/090: 0.0113 - val_recall/180: 0.9916 - val_recall/270: 0.0000e+00 - val_recall/NG: 0.0162 - val_precision/000: 0.0000e+00 - val_precision/090: 1.0000 - val_precision/180: 0.2328 - val_precision/270: 0.0000e+00 - val_precision/NG: 0.2549\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.6545 - recall/000: 0.0000e+00 - recall/090: 0.0285 - recall/180: 0.0227 - recall/270: 0.0000e+00 - recall/NG: 0.0715 - precision/000: 0.0000e+00 - precision/090: 0.1607 - precision/180: 0.2687 - precision/270: 0.0000e+00 - precision/NG: 0.5378 - val_loss: 0.8885 - val_recall/000: 0.0000e+00 - val_recall/090: 0.0012 - val_recall/180: 0.9110 - val_recall/270: 0.0000e+00 - val_recall/NG: 0.0013 - val_precision/000: 0.0000e+00 - val_precision/090: 1.0000 - val_precision/180: 0.2173 - val_precision/270: 0.0000e+00 - val_precision/NG: 1.0000\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.6601 - recall/000: 0.0000e+00 - recall/090: 0.0173 - recall/180: 2.0216e-04 - recall/270: 0.0000e+00 - recall/NG: 0.0000e+00 - precision/000: 0.0000e+00 - precision/090: 0.1637 - precision/180: 0.0088 - precision/270: 0.0000e+00 - precision/NG: 0.0000e+00 - val_loss: 1.5266 - val_recall/000: 0.0000e+00 - val_recall/090: 0.0000e+00 - val_recall/180: 0.0000e+00 - val_recall/270: 0.0000e+00 - val_recall/NG: 0.0072 - val_precision/000: 0.0000e+00 - val_precision/090: 0.0000e+00 - val_precision/180: 0.0000e+00 - val_precision/270: 0.0000e+00 - val_precision/NG: 0.0025\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.7389 - recall/000: 0.0000e+00 - recall/090: 0.0318 - recall/180: 0.0249 - recall/270: 0.0000e+00 - recall/NG: 3.9694e-04 - precision/000: 0.0000e+00 - precision/090: 0.0701 - precision/180: 0.0820 - precision/270: 0.0000e+00 - precision/NG: 0.0011 - val_loss: 6.6685 - val_recall/000: 0.0000e+00 - val_recall/090: 0.5248 - val_recall/180: 0.0000e+00 - val_recall/270: 0.0000e+00 - val_recall/NG: 0.0000e+00 - val_precision/000: 0.0000e+00 - val_precision/090: 0.1626 - val_precision/180: 0.0000e+00 - val_precision/270: 0.0000e+00 - val_precision/NG: 0.0000e+00\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.7070 - recall/000: 0.0000e+00 - recall/090: 0.0065 - recall/180: 0.0049 - recall/270: 0.0000e+00 - recall/NG: 0.0000e+00 - precision/000: 0.0000e+00 - precision/090: 0.0157 - precision/180: 0.0129 - precision/270: 0.0000e+00 - precision/NG: 0.0000e+00 - val_loss: 0.6446 - val_recall/000: 0.0000e+00 - val_recall/090: 0.2166 - val_recall/180: 0.0026 - val_recall/270: 0.0000e+00 - val_recall/NG: 0.0000e+00 - val_precision/000: 0.0000e+00 - val_precision/090: 0.1396 - val_precision/180: 0.0174 - val_precision/270: 0.0000e+00 - val_precision/NG: 0.0000e+00\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.7246 - recall/000: 0.0000e+00 - recall/090: 0.0275 - recall/180: 0.0119 - recall/270: 0.0000e+00 - recall/NG: 4.0233e-04 - precision/000: 0.0000e+00 - precision/090: 0.0528 - precision/180: 0.0263 - precision/270: 0.0000e+00 - precision/NG: 0.0010 - val_loss: 2.5065 - val_recall/000: 0.0000e+00 - val_recall/090: 0.0000e+00 - val_recall/180: 0.0025 - val_recall/270: 0.0000e+00 - val_recall/NG: 0.0000e+00 - val_precision/000: 0.0000e+00 - val_precision/090: 0.0000e+00 - val_precision/180: 0.3333 - val_precision/270: 0.0000e+00 - val_precision/NG: 0.0000e+00\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.7433 - recall/000: 0.0000e+00 - recall/090: 0.0161 - recall/180: 0.0061 - recall/270: 0.0000e+00 - recall/NG: 2.9982e-04 - precision/000: 0.0000e+00 - precision/090: 0.0376 - precision/180: 0.0156 - precision/270: 0.0000e+00 - precision/NG: 7.2622e-04 - val_loss: 0.7863 - val_recall/000: 0.0000e+00 - val_recall/090: 0.0000e+00 - val_recall/180: 0.0000e+00 - val_recall/270: 0.0000e+00 - val_recall/NG: 0.0000e+00 - val_precision/000: 0.0000e+00 - val_precision/090: 0.0000e+00 - val_precision/180: 0.0000e+00 - val_precision/270: 0.0000e+00 - val_precision/NG: 0.0000e+00\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.7139 - recall/000: 0.0000e+00 - recall/090: 0.0030 - recall/180: 0.0023 - recall/270: 0.0000e+00 - recall/NG: 9.8213e-05 - precision/000: 0.0000e+00 - precision/090: 0.0065 - precision/180: 0.0067 - precision/270: 0.0000e+00 - precision/NG: 2.4697e-04 - val_loss: 0.8371 - val_recall/000: 0.0000e+00 - val_recall/090: 0.0000e+00 - val_recall/180: 0.0023 - val_recall/270: 0.0000e+00 - val_recall/NG: 0.0000e+00 - val_precision/000: 0.0000e+00 - val_precision/090: 0.0000e+00 - val_precision/180: 0.0015 - val_precision/270: 0.0000e+00 - val_precision/NG: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f25b1def550>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = \"/data/isabelle/wzs_p1_dip/degree_NG_isa\"\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "callback_TB = tf.keras.callbacks.TensorBoard(logdir, write_graph=False, profile_batch=0)\n",
    "ms = model_structure(\"ResNet50\", [32,32,3], 5)\n",
    "ms.compile(\"adam\", \"categorical_crossentropy\", metrics=metrics)\n",
    "\n",
    "ms.fit(train_ds_degree, validation_data=valid_ds_degree,\n",
    "          epochs=HPARAMS.epochs,steps_per_epoch=HPARAMS.steps_per_epoch,\n",
    "          callbacks=[callback, callback_TB], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['degree'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:759 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:409 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py:176 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py:612 update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py:3301 sparse_categorical_accuracy\n        y_true = array_ops.squeeze(y_true, [-1])\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:4259 squeeze\n        return gen_array_ops.squeeze(input, axis, name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:10044 squeeze\n        \"Squeeze\", input=input, squeeze_dims=axis, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3485 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1975 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 5 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](IteratorGetNext:2)' with input shapes: [?,5].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8e9ea295f18d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m ms.fit(train_ds_degree, validation_data=valid_ds_degree,\n\u001b[1;32m      9\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHPARAMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHPARAMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           callbacks=[callback, callback_TB], verbose=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:759 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:409 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py:176 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py:612 update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py:3301 sparse_categorical_accuracy\n        y_true = array_ops.squeeze(y_true, [-1])\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:4259 squeeze\n        return gen_array_ops.squeeze(input, axis, name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:10044 squeeze\n        \"Squeeze\", input=input, squeeze_dims=axis, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3485 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1975 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 5 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](IteratorGetNext:2)' with input shapes: [?,5].\n"
     ]
    }
   ],
   "source": [
    "logdir = \"/data/isabelle/wzs_p1_dip/degree_NG_isa_acc\"\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "callback_TB = tf.keras.callbacks.TensorBoard(logdir, write_graph=False, profile_batch=0)\n",
    "ms = model_structure(\"InceptionV3\", [75,75,3], 5)\n",
    "ms.compile(\"adam\", \"categorical_crossentropy\", metrics=metrics)\n",
    "\n",
    "ms.fit(train_ds_degree, validation_data=valid_ds_degree,\n",
    "          epochs=HPARAMS.epochs,steps_per_epoch=HPARAMS.steps_per_epoch,\n",
    "          callbacks=[callback, callback_TB], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_train_ds = train_ds_degree.map(convert_for_adv, tf.data.experimental.AUTOTUNE)\n",
    "adv_valid_ds = valid_ds_degree.map(convert_for_adv, tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f68c12d04c0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f68be198430> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Cannot perturb features dict_keys(['degree'])WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f68c12d04c0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f68be198430> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f68c12d04c0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f68be198430> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 92s 915ms/step - loss: 0.1269 - categorical_accuracy: 0.5784 - categorical_crossentropy: 0.1057 - scaled_adversarial_loss: 0.0212 - val_loss: 1.1384 - val_categorical_accuracy: 0.2027 - val_categorical_crossentropy: 0.9487 - val_scaled_adversarial_loss: 0.1897\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 88s 884ms/step - loss: 0.4055 - categorical_accuracy: 0.5093 - categorical_crossentropy: 0.3379 - scaled_adversarial_loss: 0.0676 - val_loss: 2.0636 - val_categorical_accuracy: 0.1940 - val_categorical_crossentropy: 1.7197 - val_scaled_adversarial_loss: 0.3440\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 88s 883ms/step - loss: 0.5470 - categorical_accuracy: 0.4365 - categorical_crossentropy: 0.4559 - scaled_adversarial_loss: 0.0912 - val_loss: 0.8848 - val_categorical_accuracy: 0.4487 - val_categorical_crossentropy: 0.7372 - val_scaled_adversarial_loss: 0.1475\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 88s 884ms/step - loss: 0.4749 - categorical_accuracy: 0.4999 - categorical_crossentropy: 0.3957 - scaled_adversarial_loss: 0.0791 - val_loss: 0.4463 - val_categorical_accuracy: 0.8655 - val_categorical_crossentropy: 0.3719 - val_scaled_adversarial_loss: 0.0744\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 89s 889ms/step - loss: 0.4844 - categorical_accuracy: 0.4989 - categorical_crossentropy: 0.4037 - scaled_adversarial_loss: 0.0807 - val_loss: 0.9218 - val_categorical_accuracy: 0.1727 - val_categorical_crossentropy: 0.7681 - val_scaled_adversarial_loss: 0.1537\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 89s 886ms/step - loss: 0.4939 - categorical_accuracy: 0.4869 - categorical_crossentropy: 0.4116 - scaled_adversarial_loss: 0.0823 - val_loss: 0.8078 - val_categorical_accuracy: 0.6490 - val_categorical_crossentropy: 0.6731 - val_scaled_adversarial_loss: 0.1346\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 90s 903ms/step - loss: 0.5218 - categorical_accuracy: 0.4490 - categorical_crossentropy: 0.4348 - scaled_adversarial_loss: 0.0870 - val_loss: 0.5401 - val_categorical_accuracy: 0.7533 - val_categorical_crossentropy: 0.4501 - val_scaled_adversarial_loss: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6884e50358>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = \"/data/isabelle/wzs_p1_dip/degree_NG_isa_adv\"\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "callback_TB = tf.keras.callbacks.TensorBoard(logdir, write_graph=False, profile_batch=0)\n",
    "adv_config = nsl.configs.make_adv_reg_config(\n",
    "    multiplier=HPARAMS.adv_multiplier,\n",
    "    adv_step_size=HPARAMS.adv_step_size,\n",
    ")\n",
    "ms = model_structure(\"Xception\", [75,75,3], 5)\n",
    "model = nsl.keras.AdversarialRegularization(\n",
    "    ms, label_keys=[\"degree\"], adv_config=adv_config)\n",
    "\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=metrics)\n",
    "\n",
    "model.fit(adv_train_ds, validation_data=adv_valid_ds,\n",
    "          epochs=HPARAMS.epochs,steps_per_epoch=HPARAMS.steps_per_epoch,\n",
    "          callbacks=[callback, callback_TB], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-08 01:02:35.434896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "E1208 01:02:37.149086 140707835742016 program.py:312] TensorBoard could not bind to port 6006, it was already in use\n",
      "ERROR: TensorBoard could not bind to port 6006, it was already in use\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir=\"/data/isabelle/wzs_p1_dip/degree_NG_isa_adv\" --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_images, labels, predictions = [], [], []\n",
    "\n",
    "for batch in test_set_for_adv_model:\n",
    "  perturbed_batch = reference_model.perturb_on_batch(batch)\n",
    "  # Clipping makes perturbed examples have the same range as regular ones.\n",
    "  perturbed_batch[IMAGE_INPUT_NAME] = tf.clip_by_value(                          \n",
    "      perturbed_batch[IMAGE_INPUT_NAME], 0.0, 1.0)\n",
    "  y_true = perturbed_batch.pop(LABEL_INPUT_NAME)\n",
    "  perturbed_images.append(perturbed_batch[IMAGE_INPUT_NAME].numpy())\n",
    "  labels.append(y_true.numpy())\n",
    "  predictions.append({})\n",
    "  for name, model in models_to_eval.items():\n",
    "    y_pred = model(perturbed_batch)\n",
    "    metrics[name](y_true, y_pred)\n",
    "    predictions[-1][name] = tf.argmax(y_pred, axis=-1).numpy()\n",
    "\n",
    "for name, metric in metrics.items():\n",
    "  print('%s model accuracy: %f' % (name, metric.result().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
